{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Iterative Subgraph Screening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo shows how to use the Non-Iterative Screening class. The use of this tool will be explained by first generating simulation data. The correlation values for each node will then be generated and the signal subgraph will be estimated. Additionally, the accuracy of the correlation values will be shown by plotting the ROC curve and finding the AUC metric for that plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(8889)\n",
    "from graspy.simulations import sbm\n",
    "from graspy.plot import heatmap\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subgraph Screening uses rows of adjacency matrices as feature vectors for each node, and finds the correlation of those feature vectors with a covariate of interest. Non-Iterative screening is the simplest form of subgraph screening. \n",
    "\n",
    "Say there are m graphs and thus m labels. The correlation values found from screening are \n",
    "\n",
    "\\begin{align*}\n",
    "c_{u} = MGC\\left(\\left\\{(\\hat{X_{i}}[u,\\cdot], Y_{i})\\right\\}^{m}_{i = 1}\\right)\n",
    "\\end{align*}\n",
    "\n",
    "for covariates of interest $\\left\\{ Y_{i} \\in \\mathbb{R}, i = 1, ..., m\\right\\}$ and feature vectors $\\hat{X_{i}}[u,.] = A_{i}[u,\\cdot]$, where $A_{i}[u,\\cdot]$ is the set of corresponding rows in the adjacency matricies. \n",
    "\n",
    "For non-iterative screening, the correlation values for each node are returned in an array. Also, every node with correlation value higher than a set threshold value $c$ are returned. This is the estimated signal subgraph $\\hat{S} = \\left\\{u \\in V|c_{u} > c\\right\\}$, where $V = [n]$ for adjacency matrices in $\\mathbb{R}^{n \\ \\times \\ n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Mock Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One has to start by writing a function that will first generate simulation data. The simulation data in this case will be a tensor of sbms, each belonging to one of some given number of possible classes. Those sbms will be placed at random indicies throughout the tensor and represent the adjacency matricies of each graph. This function will then generate an array of labels that identifies the class of each adjacency matrix in the data tensor.\n",
    "\n",
    "The function takes in the desired total number of graphs to be generated, the dimension of each adjacency matrix, a vector with the number of nodes in each community, a tensor of different probability matricies that each will be used to create a different class, and a vector with the percentages of the total number of graphs that will be in each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def data_generator(num_graphs, N, n, prob_tensor, percent_vec):\n",
    "    \n",
    "    # Getting the number of classes\n",
    "    num_types = len(percent_vec)\n",
    "\n",
    "    # Getting vector with the number of graphs in each class\n",
    "    num = [int(num_graphs * a) for a in percent_vec]\n",
    "\n",
    "    data = np.zeros((num_graphs, N, N))\n",
    "    y_label = np.zeros((num_graphs, 1))\n",
    "\n",
    "    # Creates vector of random indices to randomly distribute graphs in tensor\n",
    "    L_ind = random.sample(range(0, num_graphs), num_graphs)\n",
    "\n",
    "    # Loop for creating the returns\n",
    "    for i in range(num_types):\n",
    "\n",
    "        # Create tensor that will contain all of the graphs of one type\n",
    "        types = np.zeros((num[i], N, N))\n",
    "\n",
    "        # Put all the graphs of one type into \"types\" tensor\n",
    "        for j in range(len(types)):\n",
    "            types[j] = sbm(n=n, p=prob_tensor[i])\n",
    "\n",
    "        # Assigns all of the graphs in \"types\" to random indices in data\n",
    "        data[L_ind[: num[i]]] = types\n",
    "\n",
    "        # Create corresponding labels\n",
    "        y_label[L_ind[: num[i]]] = int(i)\n",
    "\n",
    "        # Get rid of used indices\n",
    "        L_ind = L_ind[num[i] :]\n",
    "\n",
    "    return data, y_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown below is how to use the data_generator function to generate a data set consisting of 100 different 200 by 200 adjacency matricies. Each adjacency matrix has two communities, one made up of 20 nodes and the other made up of 180 nodes. The community of 20 nodes is the signal subgraph since it is the only subset of nodes that has a different probability depending on the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor of different probability matricies for each sbm type\n",
    "prob_tensor = np.zeros((2, 2, 2))\n",
    "prob_tensor[0] = [[0.3, 0.2], [0.2, 0.3]]\n",
    "prob_tensor[1] = [[0.4, 0.2], [0.2, 0.3]]\n",
    "\n",
    "n = [20, 180]\n",
    "percent_vec = np.asarray([0.50, 0.50])\n",
    "\n",
    "data_samp, y_label_samp = data_generator(100, 200, n, prob_tensor, percent_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that data has been generated, it is possible to use the Non-Iterative Screening class. The fit function will generate the array of correlation values as a class attribute and the fit_transform function will output the signal subgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspy.subgraph import NonItScreen\n",
    "\n",
    "# Screening with Multiscale Graph Correlation (MGC)\n",
    "screen = NonItScreen(\"mgc\", 0.001)\n",
    "\n",
    "#Correlations\n",
    "screen.fit(data_samp, y_label_samp)\n",
    "\n",
    "#Estimated Signal Subgraph\n",
    "S_hat = screen.fit_transform(data_samp, y_label_samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the first matrix in the data set data_samp is presentated as a heatmap. The signal subgraph for this adjacency matrix is then presentated as a heatmap afterward. Lastly, since the indicides of the nodes that make up the Signal Subgraph become a class attribute after the fit_transform function is called, these indicies are presented as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(data_samp[0], title='Entire Graph for One Data Entry')\n",
    "heatmap(S_hat[0], title='Estimated Signal Subgraph for Same Entry')\n",
    "print(\"Estimation for the Signal Subgraph Nodes:\")\n",
    "print(screen.subgraph_verts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing one can show is the accuracy of the generated array of correlation values. \n",
    "\n",
    "The closer the correlation between a node and a covariate is to 1, the more likely that node is in the Signal Subgraph. Thus, one can generate a vector of labels for each node, where the entry is 1 for each Signal Subgraph node and 0 for every other node. The correlation array and the aforemnetioned label vector can then be plugged into Sklearn's roc_curve function. This will provide the false positive rate (fpr) and true positive rate (tpr). \n",
    "\n",
    "Those can be plotted and subsequently the AUC can be found using Sklearn's auc function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "#Create signal subgraph label vector, \n",
    "#indicating which nodes are in the signal subgraph.\n",
    "ss_label = np.zeros(200)\n",
    "ss_label[:20] = 1\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(ss_label, screen.corrs)\n",
    "sns.set_context(\"talk\", font_scale=0.90)\n",
    "plt.title(\"ROC Curve for Accuracy of MGC Non-Iterative Screening\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.step(fpr, tpr, label=\"Non-Iterative MGC Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "auc_val = metrics.auc(fpr, tpr)\n",
    "print(\"The AUC value is the area under the ROC curve.\")\n",
    "print(\"This is a measurement of the accuracy of the estimation.\")\n",
    "print(\"The closer to 1, the better.\")\n",
    "print(\"AUC Value:\", auc_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
